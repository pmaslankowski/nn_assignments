{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "**Submission deadline: last lab session before or on Wednesday 25.10.17**\n",
    "\n",
    "**Points: 13 + 1 bonus points**\n",
    "\n",
    "\n",
    "## Downloading this notebook\n",
    "\n",
    "This assignment is an Jupyter notebook. Download it by cloning https://github.com/janchorowski/nn_assignments. Follow the instructions in its README for instructions. Whenever possible, add your solutions to the notebook.\n",
    "\n",
    "Please email us about any problems with it - we will try to correct them quickly. Also, please do not hesitate to use GitHub’s pull requests to send us corrections!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 [2p] Bayes' Theorem\n",
    "\n",
    "Bayes' theorem allows to reason about conditional probabilities of causes and their effects:\n",
    "\n",
    "\\begin{equation}\n",
    "p(A,B)=p(A|B)p(B)=p(B|A)p(A)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "p(A|B) = \\frac{p(B|A)p(A)}{p(B)}\n",
    "\\end{equation}\n",
    "\n",
    "Bayes' theorem allows us to reason about probabilities of causes, when\n",
    "we observe their results.  Instead of directly answering the hard\n",
    "question $p(\\text{cause}|\\text{result})$ we can instead separately\n",
    "work out the marginal probabilities of causes $p(\\text{cause})$ and\n",
    "carefully study their effects $p(\\text{effect}|\\text{cause})$.\n",
    "\n",
    "Solve the following using Bayes' theorem.\n",
    "\n",
    "1. **[1p]** There are two boxes on the table: box \\#1 holds two\n",
    "  black balls and eight red ones, box \\#2 holds 5 black ones and\n",
    "  5 red ones. We pick a box at random (with equal probabilities),\n",
    "  and then a ball from that box.\n",
    "  1. What is the probability, that the\n",
    "  ball came from box \\#1 if we happened to pick a red ball?\n",
    "  \n",
    "1. **[1p]** The government has started a preventive program of\n",
    "  mandatory tests for the Ebola virus. Mass testing method is\n",
    "  imprecise, yielding 1% of false positives (healthy, but the test\n",
    "  indicates the virus) and 1% of false negatives (\n",
    "  having the virus but healthy according to test results).\n",
    "  As Ebola is rather infrequent, lets assume that it occurs in\n",
    "  one in a million people in Europe.\n",
    "  1. What is the probability,\n",
    "  that a random European, who has been tested positive for Ebola\n",
    "  virus, is indeed a carrier?\n",
    "  2. Suppose we have an additional information, that the person has just\n",
    "  arrived from a country where one in a thousand people is a carrier.\n",
    "  How much will be the increase in probability?\n",
    "  3. How accurate should be the test, for a 80% probability of true\n",
    "  positive in a European?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that we took ball from box 1 if the ball was red equals: 0.615384615385\nProbability that random European who has been tested positive is indeed a carrier equals: 0.000989030749865\nProbability that random European who returned from another country and has been tested positive is indeed a carrier equals: 0.989030749865\nAccuracy of the test should equal: 2.50001875014e-06\n"
     ]
    }
   ],
   "source": [
    "p_red_and_1 = 0.5 * 0.8 # probability of choosing box 1 and taking red ball\n",
    "p_red = 0.5 * 0.8 + 0.5 * 0.5 # probability of taking red ball (from box 1 or box 2)\n",
    "p_1_if_red = p_red_and_1 / p_red # probability of choosing box 1, when we know that we took red ball\n",
    "print('Probability that we took ball from box 1 if the ball was red equals: {}'.format(p_1_if_red))\n",
    "\n",
    "# We want to compute p_carrier_positive - probability of being ebola carrier if test gave positive result\n",
    "p_positive_if_carrier = 0.99 # = 1 - p_negative_if_carrier = 1 - 0.01\n",
    "p_carrier_in_europe = 10e-6\n",
    "p_positive_if_not_carrier = 0.01\n",
    "p_positive = p_carrier_in_europe * p_positive_if_carrier + (1 - p_carrier_in_europe) * p_positive_if_not_carrier\n",
    "p_carrier_if_positive = p_positive_if_carrier * p_carrier_in_europe / p_positive # Bayes Theorem, (1)\n",
    "print('Probability that random European who has been tested positive is indeed a carrier equals: {}'.format(p_carrier_if_positive))\n",
    "\n",
    "p_carrier_another_country = 10e-3\n",
    "p_carrier_if_positive_another_country = p_positive_if_carrier * p_carrier_another_country / p_positive\n",
    "print('Probability that random European who returned from ' +\n",
    "      'another country and has been tested positive is indeed ' +\n",
    "      'a carrier equals: {}'.format(p_carrier_if_positive_another_country))\n",
    "\n",
    "p_carrier_if_positive_expected = 0.8\n",
    "accuracy = (p_carrier_if_positive_expected-1)*p_carrier_in_europe / (p_carrier_if_positive_expected*(2*p_carrier_in_europe-1)-p_carrier_in_europe)\n",
    "print('Accuracy of the test should equal: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 [2p + 1b] Naive Bayes Classifier\n",
    "\n",
    "The Bayes' theorem allows us to construct a classifier in which we\n",
    "model how the data is generated. Here we will describe a\n",
    "simple and popular example of such a classifier called the naive\n",
    "Bayes classifier.  Despite its simplicity It is quite effective for\n",
    "classification of text documents (e.g. as spam and non-spam).\n",
    "\n",
    "Let a document be a sequence of words $D=W_1,W_2,\\ldots,W_n$ \n",
    "We will model generation of text documents as a two-stage process.\n",
    "First, document category $C_j$ is drawn at random with probability\n",
    "$p(C_j)$, also called the *a priori* probability.\n",
    "To define the class-conditional probability\n",
    "$p(D|C_j)$, we will make a simplifying (naive)\n",
    "assumption, that every word in the document is drawn independently at\n",
    "random with probability $p(W_i|C)$:\n",
    "\n",
    "\\begin{equation*}\n",
    "  p(D|C_j) = p(W_1,W_2,\\ldots,W_n | C_j) \\approx p(W_1|C_j)p(W_2|C_j)\\ldots p(W_n|C_j).\n",
    "\\end{equation*}\n",
    "\n",
    "To infer the class of a document we apply the Bayes theorem:\n",
    "\\begin{equation*}   p(C_j|D) = \\frac{p(D|C_j)p(C_j)}{p(D)} = \\frac{p(C_j)p(W_1|C_j)p(W_2|C_j)\\ldots p(W_n|C_j)}{p(D)}.\n",
    "\\end{equation*}\n",
    "Please note that since we assumed only a finite number of classes,\n",
    "we can compute the term $p(D)$ by making sure that the *a\n",
    "posteriori probabilities* $p(C_j|D)$ sum to $1$ over all classes.\n",
    "\n",
    "In this exercise we will try to mimic the language-guessing feature\n",
    "of [Google Translate](https://translate.google.com/), although\n",
    "on a much smaller scale.  We are given an input which is a\n",
    "lower-case sequence of characters (such as *\"some people like\n",
    "pineapple on their pizza\"*), and we determine whether the\n",
    "sequence's language is English, Polish or Spanish.\n",
    "We will treat each character as a separate observation.\n",
    "The numbers are taken from [Wikipedia article on letter frequency](https://en.wikipedia.org/wiki/Letter_frequency#Relative_frequencies_of_letters_in_other_languages). We display the first few rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>French</th>\n",
       "      <th>German</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Portuguese</th>\n",
       "      <th>Esperanto</th>\n",
       "      <th>Italian</th>\n",
       "      <th>Turkish</th>\n",
       "      <th>Swedish</th>\n",
       "      <th>Polish</th>\n",
       "      <th>Dutch</th>\n",
       "      <th>Danish</th>\n",
       "      <th>Icelandic</th>\n",
       "      <th>Finnish</th>\n",
       "      <th>Czech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>8.167</td>\n",
       "      <td>7.636</td>\n",
       "      <td>6.516</td>\n",
       "      <td>11.525</td>\n",
       "      <td>14.634</td>\n",
       "      <td>12.117</td>\n",
       "      <td>11.745</td>\n",
       "      <td>12.920</td>\n",
       "      <td>9.383</td>\n",
       "      <td>10.503</td>\n",
       "      <td>7.486</td>\n",
       "      <td>6.025</td>\n",
       "      <td>10.110</td>\n",
       "      <td>12.217</td>\n",
       "      <td>8.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1.492</td>\n",
       "      <td>0.901</td>\n",
       "      <td>1.886</td>\n",
       "      <td>2.215</td>\n",
       "      <td>1.043</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.927</td>\n",
       "      <td>2.844</td>\n",
       "      <td>1.535</td>\n",
       "      <td>1.740</td>\n",
       "      <td>1.584</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.043</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>2.782</td>\n",
       "      <td>3.260</td>\n",
       "      <td>2.732</td>\n",
       "      <td>4.019</td>\n",
       "      <td>3.882</td>\n",
       "      <td>0.776</td>\n",
       "      <td>4.501</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.486</td>\n",
       "      <td>3.895</td>\n",
       "      <td>1.242</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>4.253</td>\n",
       "      <td>3.669</td>\n",
       "      <td>5.076</td>\n",
       "      <td>5.010</td>\n",
       "      <td>4.992</td>\n",
       "      <td>3.044</td>\n",
       "      <td>3.736</td>\n",
       "      <td>5.206</td>\n",
       "      <td>4.702</td>\n",
       "      <td>3.725</td>\n",
       "      <td>5.933</td>\n",
       "      <td>5.858</td>\n",
       "      <td>1.575</td>\n",
       "      <td>1.043</td>\n",
       "      <td>3.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>12.702</td>\n",
       "      <td>14.715</td>\n",
       "      <td>16.396</td>\n",
       "      <td>12.181</td>\n",
       "      <td>12.570</td>\n",
       "      <td>8.995</td>\n",
       "      <td>11.792</td>\n",
       "      <td>9.912</td>\n",
       "      <td>10.149</td>\n",
       "      <td>7.352</td>\n",
       "      <td>18.910</td>\n",
       "      <td>15.453</td>\n",
       "      <td>6.418</td>\n",
       "      <td>7.968</td>\n",
       "      <td>7.562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>French</th>\n",
       "      <th>German</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Portuguese</th>\n",
       "      <th>Esperanto</th>\n",
       "      <th>Italian</th>\n",
       "      <th>Turkish</th>\n",
       "      <th>Swedish</th>\n",
       "      <th>Polish</th>\n",
       "      <th>Dutch</th>\n",
       "      <th>Danish</th>\n",
       "      <th>Icelandic</th>\n",
       "      <th>Finnish</th>\n",
       "      <th>Czech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>8.167</td>\n",
       "      <td>7.636</td>\n",
       "      <td>6.516</td>\n",
       "      <td>11.525</td>\n",
       "      <td>14.634</td>\n",
       "      <td>12.117</td>\n",
       "      <td>11.745</td>\n",
       "      <td>12.920</td>\n",
       "      <td>9.383</td>\n",
       "      <td>10.503</td>\n",
       "      <td>7.486</td>\n",
       "      <td>6.025</td>\n",
       "      <td>10.110</td>\n",
       "      <td>12.217</td>\n",
       "      <td>8.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1.492</td>\n",
       "      <td>0.901</td>\n",
       "      <td>1.886</td>\n",
       "      <td>2.215</td>\n",
       "      <td>1.043</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.927</td>\n",
       "      <td>2.844</td>\n",
       "      <td>1.535</td>\n",
       "      <td>1.740</td>\n",
       "      <td>1.584</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.043</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>2.782</td>\n",
       "      <td>3.260</td>\n",
       "      <td>2.732</td>\n",
       "      <td>4.019</td>\n",
       "      <td>3.882</td>\n",
       "      <td>0.776</td>\n",
       "      <td>4.501</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.486</td>\n",
       "      <td>3.895</td>\n",
       "      <td>1.242</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>4.253</td>\n",
       "      <td>3.669</td>\n",
       "      <td>5.076</td>\n",
       "      <td>5.010</td>\n",
       "      <td>4.992</td>\n",
       "      <td>3.044</td>\n",
       "      <td>3.736</td>\n",
       "      <td>5.206</td>\n",
       "      <td>4.702</td>\n",
       "      <td>3.725</td>\n",
       "      <td>5.933</td>\n",
       "      <td>5.858</td>\n",
       "      <td>1.575</td>\n",
       "      <td>1.043</td>\n",
       "      <td>3.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>12.702</td>\n",
       "      <td>14.715</td>\n",
       "      <td>16.396</td>\n",
       "      <td>12.181</td>\n",
       "      <td>12.570</td>\n",
       "      <td>8.995</td>\n",
       "      <td>11.792</td>\n",
       "      <td>9.912</td>\n",
       "      <td>10.149</td>\n",
       "      <td>7.352</td>\n",
       "      <td>18.910</td>\n",
       "      <td>15.453</td>\n",
       "      <td>6.418</td>\n",
       "      <td>7.968</td>\n",
       "      <td>7.562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from StringIO import StringIO\n",
    "\n",
    "wiki_table = u\"\"\"English|French|German|Spanish|Portuguese|Esperanto|Italian|Turkish|Swedish|Polish|Dutch|Danish|Icelandic|Finnish|Czech\\na|8.167|7.636|6.516|11.525|14.634|12.117|11.745|12.920|9.383|10.503|7.486|6.025|10.110|12.217|8.421\\nb|1.492|0.901|1.886|2.215|1.043|0.980|0.927|2.844|1.535|1.740|1.584|2.000|1.043|0.281|0.822\\nc|2.782|3.260|2.732|4.019|3.882|0.776|4.501|1.463|1.486|3.895|1.242|0.565|0|0.281|0.740\\nd|4.253|3.669|5.076|5.010|4.992|3.044|3.736|5.206|4.702|3.725|5.933|5.858|1.575|1.043|3.475\\ne|12.702|14.715|16.396|12.181|12.570|8.995|11.792|9.912|10.149|7.352|18.91|15.453|6.418|7.968|7.562\\nf|2.228|1.066|1.656|0.692|1.023|1.037|1.153|0.461|2.027|0.143|0.805|2.406|3.013|0.194|0.084\\ng|2.015|0.866|3.009|1.768|1.303|1.171|1.644|1.253|2.862|1.731|3.403|4.077|4.241|0.392|0.092\\nh|6.094|0.737|4.577|0.703|0.781|0.384|0.636|1.212|2.090|1.015|2.380|1.621|1.871|1.851|1.356\\ni|6.966|7.529|6.550|6.247|6.186|10.012|10.143|9.600|5.817|8.328|6.499|6.000|7.578|10.817|6.073\\nj|0.153|0.613|0.268|0.493|0.397|3.501|0.011|0.034|0.614|1.836|1.46|0.730|1.144|2.042|1.433\\nk|0.772|0.049|1.417|0.011|0.015|4.163|0.009|5.683|3.140|2.753|2.248|3.395|3.314|4.973|2.894\\nl|4.025|5.456|3.437|4.967|2.779|6.104|6.510|5.922|5.275|2.564|3.568|5.229|4.532|5.761|3.802\\nm|2.406|2.968|2.534|3.157|4.738|2.994|2.512|3.752|3.471|2.515|2.213|3.237|4.041|3.202|2.446\\nn|6.749|7.095|9.776|6.712|4.446|7.955|6.883|7.987|8.542|6.237|10.032|7.240|7.711|8.826|6.468\\no|7.507|5.796|2.594|8.683|9.735|8.779|9.832|2.976|4.482|6.667|6.063|4.636|2.166|5.614|6.695\\np|1.929|2.521|0.670|2.510|2.523|2.755|3.056|0.886|1.839|2.445|1.57|1.756|0.789|1.842|1.906\\nq|0.095|1.362|0.018|0.877|1.204|0|0.505|0|0.020|0|0.009|0.007|0|0.013|0.001\\nr|5.987|6.693|7.003|6.871|6.530|5.914|6.367|7.722|8.431|5.243|6.411|8.956|8.581|2.872|4.799\\ns|6.327|7.948|7.270|7.977|6.805|6.092|4.981|3.014|6.590|5.224|3.73|5.805|5.630|7.862|5.212\\nt|9.056|7.244|6.154|4.632|4.336|5.276|5.623|3.314|7.691|2.475|6.79|6.862|4.953|8.750|5.727\\nu|2.758|6.311|4.166|2.927|3.639|3.183|3.011|3.235|1.919|2.062|1.99|1.979|4.562|5.008|2.160\\nv|0.978|1.838|0.846|1.138|1.575|1.904|2.097|0.959|2.415|0.012|2.85|2.332|2.437|2.250|5.344\\nw|2.360|0.074|1.921|0.017|0.037|0|0.033|0|0.142|5.813|1.52|0.069|0|0.094|0.016\\nx|0.150|0.427|0.034|0.215|0.253|0|0.003|0|0.159|0.004|0.036|0.028|0.046|0.031|0.027\\ny|1.974|0.128|0.039|1.008|0.006|0|0.020|3.336|0.708|3.206|0.035|0.698|0.900|1.745|1.043\\nz|0.074|0.326|1.134|0.467|0.470|0.494|1.181|1.500|0.070|4.852|1.39|0.034|0|0.051|1.503\\nà|0|0.486|0|0|0.072|0|0.635|0|0|0|0|0|0|0|0\\nâ|0|0.051|0|0|0.562|0|0|0|0|0|0|0|0|0|0\\ná|0|0|0|0.502|0.118|0|0|0|0|0|0|0|1.799|0|0.867\\nå|0|0|0|0|0|0|0|0|1.338|0|0|1.190|0|0.003|0\\nä|0|0|0.578|0|0|0|0|0|1.797|0|0|0|0|3.577|0\\nã|0|0|0|0|0.733|0|0|0|0|0|0|0|0|0|0\\ną|0|0|0|0|0|0|0|0|0|0.699|0|0|0|0|0\\næ|0|0|0|0|0|0|0|0|0|0|0|0.872|0.867|0|0\\nœ|0|0.018|0|0|0|0|0|0|0|0|0|0|0|0|0\\nç|0|0.085|0|0|0.530|0|0|1.156|0|0|0|0|0|0|0\\nĉ|0|0|0|0|0|0.657|0|0|0|0|0|0|0|0|0\\nć|0|0|0|0|0|0|0|0|0|0.743|0|0|0|0|0\\nč|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0.462\\nď|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0.015\\nð|0|0|0|0|0|0|0|0|0|0|0|0|4.393|0|0\\nè|0|0.271|0|0|0|0|0.263|0|0|0|0|0|0|0|0\\né|0|1.504|0|0.433|0.337|0|0|0|0|0|0|0|0.647|0|0.633\\nê|0|0.218|0|0|0.450|0|0|0|0|0|0|0|0|0|0\\në|0|0.008|0|0|0|0|0|0|0|0|0|0|0|0|0\\nę|0|0|0|0|0|0|0|0|0|1.035|0|0|0|0|0\\ně|0|0|0|0|0|0|0|0|0|0|0|0|0|0|1.222\\nĝ|0|0|0|0|0|0.691|0|0|0|0|0|0|0|0|0\\nğ|0|0|0|0|0|0|0|1.125|0|0|0|0|0|0|0\\nĥ|0|0|0|0|0|0.022|0|0|0|0|0|0|0|0|0\\nî|0|0.045|0|0|0|0|0|0|0|0|0|0|0|0|0\\nì|0|0|0|0|0|0|0.030|0|0|0|0|0|0|0|0\\ní|0|0|0|0.725|0.132|0|0|0|0|0|0|0|1.570|0|1.643\\nï|0|0.005|0|0|0|0|0|0|0|0|0|0|0|0|0\\nı|0|0|0|0|0|0|0|5.114|0|0|0|0|0|0|0\\nĵ|0|0|0|0|0|0.055|0|0|0|0|0|0|0|0|0\\nł|0|0|0|0|0|0|0|0|0|2.109|0|0|0|0|0\\nñ|0|0|0|0.311|0|0|0|0|0|0|0|0|0|0|0\\nń|0|0|0|0|0|0|0|0|0|0.362|0|0|0|0|0\\nň|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0.007\\nò|0|0|0|0|0|0|0.002|0|0|0|0|0|0|0|0\\nö|0|0|0.443|0|0|0|0|0.777|1.305|0|0|0|0.777|0.444|0\\nô|0|0.023|0|0|0.635|0|0|0|0|0|0|0|0|0|0\\nó|0|0|0|0.827|0.296|0|0|0|0|1.141|0|0|0.994|0|0.024\\nõ|0|0|0|0|0.040|0|0|0|0|0|0|0|0|0|0\\nø|0|0|0|0|0|0|0|0|0|0|0|0.939|0|0|0\\nř|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0.380\\nŝ|0|0|0|0|0|0.385|0|0|0|0|0|0|0|0|0\\nş|0|0|0|0|0|0|0|1.780|0|0|0|0|0|0|0\\nś|0|0|0|0|0|0|0|0|0|0.814|0|0|0|0|0\\nš|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0.688\\nß|0|0|0.307|0|0|0|0|0|0|0|0|0|0|0|0\\nť|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0.006\\nþ|0|0|0|0|0|0|0|0|0|0|0|0|1.455|0|0\\nù|0|0.058|0|0|0|0|0.166|0|0|0|0|0|0|0|0\\nú|0|0|0|0.168|0.207|0|0|0|0|0|0|0|0.613|0|0.045\\nû|0|0.060|0|0|0|0|0|0|0|0|0|0|0|0|0\\nŭ|0|0|0|0|0|0.520|0|0|0|0|0|0|0|0|0\\nü|0|0|0.995|0.012|0.026|0|0|1.854|0|0|0|0|0|0|0\\nů|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0.204\\ný|0|0|0|0|0|0|0|0|0|0|0|0|0.228|0|0.995\\nź|0|0|0|0|0|0|0|0|0|0.078|0|0|0|0|0\\nż|0|0|0|0|0|0|0|0|0|0.706|0|0|0|0|0\\nž|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0.721\"\"\"\n",
    "df = pd.read_table(StringIO(wiki_table), sep='|', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the language classifier and answer the following:\n",
    "\n",
    "1. **[0.5p]** Naive Bayes can be implemented\n",
    "    either by multiplying probabilities or by adding\n",
    "    log-probabilities. Which one is better and why?\n",
    "2. **[1.5p]** What is the language of the following phrases, according to the classifier (below in a code cell)? Assume equal prior language probabilities $P(C)$.\n",
    "3. **[0-1 bonus]** What happens when a Naive Bayes classifier\n",
    "      is applied to a document with out-of-vocabulary words? Propose\n",
    "      some solutions. Relate them to the concept of Bayesian\n",
    "      priors discussed during the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "sentences = [\n",
    "    u\"No dejes para mañana lo que puedas hacer hoy.\",\n",
    "    u\"Przed wyruszeniem w drogę należy zebrać drużynę.\",\n",
    "    u\"Żeby zrozumieć rekurencję, należy najpierw zrozumieć rekurencję.\",\n",
    "    u\"Si vale la pena hacerlo vale la pena hacerlo bien.\",\n",
    "    u\"Experience is what you get when you didn't get what you wanted.\",\n",
    "    u\"Należy prowokować intelekt, nie intelektualistów.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-85163503612b>, line 4)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-85163503612b>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    print 'Languages:', ','.join(langs)\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# We can easily access the data.\n",
    "langs = list(df)\n",
    "letters = list(df.index)\n",
    "print 'Languages:', ','.join(langs)\n",
    "print 'Letters:', ', '.join(letters)\n",
    "print u'P(ę|Polish) =', df.loc[u'ę'.encode('utf-8'), 'Polish']\n",
    "print u'P(ñ|Spanish)=', df.loc[sentences[0][16].encode('utf-8'), 'Spanish']\n",
    "\n",
    "# Normalize values to a probability distribution\n",
    "df_norm = df.divide(df.values.sum(0) * len(langs))\n",
    "#print df_norm.values.sum(0)\n",
    "\n",
    "import numpy as np\n",
    "def naive_bayes(sent, langs, df_norm):\n",
    "    \"\"\"Returns the most probable language of a sentence\"\"\"\n",
    "    sent_processed = [ch.encode('utf-8') for ch in sent.lower() if ch not in [u' ', u'.', u',', u\"'\"]]\n",
    "    log_probabilities = np.log(df_norm.loc[sent_processed]).sum(axis=0, skipna=False)\n",
    "    # we assume equal prior probabilities, so these probabilities would only scale our log_probabilities\n",
    "    # and therefore we don't have to do anything more here \n",
    "    return np.argmax(log_probabilities)\n",
    "    \n",
    "\n",
    "for sent in sentences:\n",
    "   print naive_bayes(sent, langs, df_norm), ':', sent\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 [2p]\n",
    "Given observations $x_1,\\ldots,x_n$\n",
    "  coming from a certain distribution,\n",
    "  prove that MLE of a particular parameter of that distribution is equal to the sample mean $\\frac{1}{n}\\sum_{i=1}^n x_i$:\n",
    "1. Bernoulli distribution with success probability $p$ and MLE $\\hat{p}$,\n",
    "2. Gaussian distribution $\\mathcal{N}(\\mu,\\sigma)$ and MLE $\\hat{\\mu}$,\n",
    "3. Poisson distribution $\\mathit{Pois}(\\lambda)$ and MLE $\\hat{\\lambda}$.\n",
    "\n",
    "*NOTE: You can submit your solution on paper. To freeze the solution and spend late days, at minimum send a photo of your solution via e-mail.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4 [2p]\n",
    "\n",
    "1. Find simple expressions for the following functions' derivatives with respect to vector $\\mathbf{x}$.\n",
    "    1. $\\tanh(\\mathbf{x})$\n",
    "    2. $\\sigma(\\mathbf{x}) = \\frac{1}{1 + e^{-\\mathbf{x}}}$\n",
    "2. Find the following functions' gradients with respect to vector $[x, y, z]^T$:\n",
    "    1. $f_1([x, y, z]^T) = x + y$\n",
    "    2. $f_2([x, y, z]^T) = xy$\n",
    "    3. $f_3([x, y, z]^T) = x^2y^2$\n",
    "    4. $f_4([x, y, z]^T) = (x + y)^2$\n",
    "    5. $f_5([x, y, z]^T) = x^4 + x^2 y z + x y^2 z + z^4$\n",
    "    6. $f_6([x, y, z]^T) = e^{x + 2y}$\n",
    "    7. $f_7([x, y, z]^T) = \\frac{1}{x y^2}$\n",
    "    8. $f_8([x, y, z]^T) = ax + by + c$\n",
    "    9. $f_9([x, y, z]^T) = \\tanh(ax + by + c)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5 [2p]\n",
    "\n",
    "Find the following functions' gradients or Jacobians with respect to vector $\\mathbf{x}$, where $\\mathbf{x}, \\mathbf{b} \\in \\mathbb{R}^{n}$, $\\mathbf{W} \\in \\mathbb{R}^{n \\times n}$:\n",
    "\n",
    "1. **[0.5p]** $\\mathbf{W} \\mathbf{x} + \\mathbf{b}$\n",
    "2. **[0.5p]** $\\mathbf{x}^T \\mathbf{W} \\mathbf{x}$,\n",
    "3. **[0.5p]** $\\sigma(\\mathbf{W} \\mathbf{x} + \\mathbf{b})$,\n",
    "    with $\\sigma$ applied element-wise. Hint: use the Hadamard product\n",
    "    (denoted $\\circ$) for element-wise matrix multiplication.\n",
    "4. **[0.5p]** $-\\log(S(\\mathbf{x})_j)$, where $S$ is the\n",
    "    softmax function\n",
    "    (https://en.wikipedia.org/wiki/Softmax_function) and we are\n",
    "    interested in the derivative over the $j$-th output of the\n",
    "    Softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6 [2p] Linear Regression\n",
    "\n",
    "1. Implement a function generating a dataset of $n$ points\n",
    "  according to the following algorithm:\n",
    "  1. Draw $n$ points $x \\propto U(0;10)$ (uniformly distributed on $[0,10]$).\n",
    "  2. Draw $n$ points $y \\propto \\mathcal{N}(1+20x-1.3x^2, 7)$\n",
    "    (from a Gaussian distribution with $\\mu=1+20x-1.3x^2$ and $\\sigma=7$).\n",
    "\n",
    "  Prepare a dataset of 30 elements and make a scatterplot of\n",
    "  the expected value $y$ in function $x$.\n",
    "\n",
    "2. Use linear regression to fit polynomials to the\n",
    "  generated dataset. Fit polynomials of degrees zero (a constant line),\n",
    "  one, two and three. An easy way to do it is to transform each data\n",
    "  point $x$ into a vector of its powers $[1, x, x^2, \\ldots, x^m]$.\n",
    "\n",
    "  Plot the dataset and all regression curves on one figure.\n",
    "\n",
    "  **Note:** The name _linear regression_ signifies that the\n",
    "  hypothesis is linear with respect to parameters $\\Theta$.\n",
    "  However, the relationship between $x$ and $y$ is not constrained\n",
    "  to a linear one. In this exercise it is a polynomial one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xb2d3d30>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbac1d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_dataset(N):\n",
    "    X = np.random.uniform(0., 10., N)\n",
    "    Y = np.random.normal(1 + 20 * X - 1.3 * X ** 2, 7.).reshape((-1,1))\n",
    "    return X,Y\n",
    "\n",
    "data = make_dataset(30)\n",
    "scatter(data[0], data[1], color='g')\n",
    "title('Randomized points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 23.36815396   5.7305631 ] (2L,)\n[  4.28862511  18.37286888  -1.22526089] (3L,)\n[  5.77396286  16.3938513   -0.70652786  -0.03484009] (4L,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xb16ef28>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbac1fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy.linalg import inv\n",
    "\n",
    "def powers_of_X(X, degree):\n",
    "    powers = np.arange(degree + 1).reshape(-1,1)\n",
    "    return X**powers\n",
    "\n",
    "def compute_polynomial(X, Theta):\n",
    "    XP = powers_of_X(X, len(Theta) - 1) # len(Theta) x N\n",
    "    Y = Theta.reshape((1, -1)).dot(XP)\n",
    "    return Y\n",
    "\n",
    "plot_x_space = np.linspace(0,10,100)\n",
    "scatter(data[0], data[1])\n",
    "for degree in range(1,4):\n",
    "    X = powers_of_X(data[0], degree) # Matrix d x N\n",
    "    Y = data[1].reshape(1, -1)       # Matrix 1 x N\n",
    "    Theta = Y.dot(X.T).dot(inv(X.dot(X.T))).reshape(-1) # Theta = Y X.T (X X.T)^-1\n",
    "    plot(plot_x_space, compute_polynomial(plot_x_space, Theta).ravel(), \n",
    "         label=\"degree: %d\" %(degree, ))\n",
    "    print(Theta, Theta.shape)\n",
    "legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7 [1p]\n",
    "\n",
    "When the data set is small and highly dimensional (or when high degree polynomials are used) the linear regression solution may fit the noise in the data instead of capturing the general rule. We call this phenomenon overfitting and will discuss it in detail in a few lectures.\n",
    "\n",
    "One way of preventing overfitting is to force the model's parameters to be small. We call this *regularization*. Consider the following cost function:\n",
    "\n",
    "$$ J(\\Theta) = \\sum_{i=1}^N (y^{(i)} - \\Theta^T x^{(i)})^2 + \\frac{\\lambda}{2} \\Theta^T \\Theta $$\n",
    "\n",
    "Analyze datasets sampled using the following procedure:\n",
    "\n",
    "1. $x \\propto U(0;1)$: $x$ is sampled uniformly from the  $0-1$ range.\n",
    "2. $y \\propto \\mathcal{N}(\\mu=1+2x-5x^2 + 4x^3, \\sigma=0.1)$: then \n",
    "    $y$ is sampled from the Normal distribution with mean \n",
    "    $\\mu=1+2x-5x^2+4x^3$ and standard deviation $0.1$\n",
    "\n",
    "Repeat 30 times an experiment in which you sample a new training\n",
    "dataset, then fit polynomials of degree 0 to 14 and use $\\lambda$\n",
    "value from the set $\\{0, 10^{-6}, 10^{-5}, 10^{-4}, 10^{-3}, 10^{-2}, 10^{-1}\\}$.\n",
    "\n",
    "Plot the mean training and testing errors. What is the effect of increasing $\\lambda$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'NoneType'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-39ddb929c8ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mXX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mYY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoly_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_poly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-39ddb929c8ea>\u001b[0m in \u001b[0;36mmake_dataset\u001b[1;34m(N, theta, sigma)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;34m\"\"\" Sample a dataset \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msigma\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpoly_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_poly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'NoneType'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "def poly_fun(X, Theta):\n",
    "    \"\"\"Compute the value of polynomial with coefficients Theta for points in X\"\"\"\n",
    "    #\n",
    "    # TODO: Write body of the function.\n",
    "    # Return a vector of values in points from X (the same shape as X).\n",
    "    # \n",
    "\n",
    "#\n",
    "# The true polynomial relation:\n",
    "# y(x) = 1 + 2x -5x^2 + 4x^3\n",
    "#\n",
    "# TODO: write down the proper coefficients\n",
    "#\n",
    "true_poly = np.array([1., 2., -5, 4])\n",
    "\n",
    "def make_dataset(N, theta=true_poly, sigma=0.1):\n",
    "    \"\"\" Sample a dataset \"\"\"\n",
    "    X = np.random.rand(N)\n",
    "    Y = np.random.randn(N)*sigma + poly_fun(X, true_poly)\n",
    "    return X,Y\n",
    "\n",
    "\n",
    "train_data = make_dataset(30)\n",
    "XX = np.linspace(0,1,100)\n",
    "YY = poly_fun(XX, true_poly)\n",
    "scatter(train_data[0], train_data[1], label='train data', color='r')\n",
    "plot(XX, poly_fun(XX, true_poly), label='ground truth')\n",
    "legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named common",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-cc97bcdb950e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'..'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotting\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named common"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from common import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#please note: lambda is a reserved keyword in python, thus we use _lambda\n",
    "def poly_fit(data, degree, _lambda):\n",
    "    \"Fit a polynomial of a given degree and weight decay parameter C\"\n",
    "    powers = np.arange(degree + 1.0).reshape(-1,1)\n",
    "    X = data[0].reshape(1,-1)\n",
    "    Y = data[1].reshape(1,-1)\n",
    "    XX = X**powers\n",
    "    #\n",
    "    # TODO: implement the closed-form solution for Theta\n",
    "    #\n",
    "    # Please note that np.inv may be numerically unstable.\n",
    "    # It is better to use np.linalg.solve or even a QR decomposition.\n",
    "    #\n",
    "    Theta = TODO\n",
    "    return Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'NoneType'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-4aae1079cb20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#sample a single dataset for all experiments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrepetition\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_repetitions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-39ddb929c8ea>\u001b[0m in \u001b[0;36mmake_dataset\u001b[1;34m(N, theta, sigma)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;34m\"\"\" Sample a dataset \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msigma\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpoly_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_poly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'NoneType'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "lambdas = [0.0, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "degrees  = arange(15)\n",
    "\n",
    "num_repetitions = 30\n",
    "num_samples = 30\n",
    "\n",
    "train_errors = np.zeros((len(lambdas), len(degrees)))\n",
    "test_errors = np.zeros((len(lambdas), len(degrees)))\n",
    "\n",
    "#sample a single dataset for all experiments\n",
    "test_data = make_dataset(num_samples)\n",
    "\n",
    "for repetition in xrange(num_repetitions):\n",
    "    #sample a new training dataset for this repetition\n",
    "    train_data = make_dataset(num_samples)\n",
    "    #scatter(data[0], data[1])\n",
    "    for degree_i, degree in enumerate(degrees):\n",
    "        for lambda_i, _lambda in enumerate(lambdas):\n",
    "            Theta = poly_fit(train_data, degree, _lambda)\n",
    "            #\n",
    "            # TODO: compute the mean training and test errors\n",
    "            #\n",
    "            train_errors[lambda_i, degree_i] += TODO\n",
    "            test_errors[lambda_i, degree_i] += TODO\n",
    "train_errors /=  num_repetitions\n",
    "test_errors /= num_repetitions\n",
    "\n",
    "figure(figsize=(10,20))\n",
    "for lambda_i, _lambda in enumerate(lambdas):\n",
    "    subplot(len(lambdas), 1, lambda_i+1)\n",
    "    plot(degrees, train_errors[lambda_i,:], label='train')\n",
    "    plot(degrees, test_errors[lambda_i,:],  label='test')\n",
    "    ylim(0,0.1)\n",
    "    title('lambda=%g'%(_lambda,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
